## Machine_Learning-Clustering and retrieval
**4/4 in Machine_Learning-Specialization————Clustering and retrieval**

<br /> <br />
---
### Course-Content 学习内容
--
* ** Nearest Neighbor Search最近邻搜索**

将深入了解算法的两个关键组件：用于测量数据点对之间的相似性的数据表示和度量。 将检查初始最近邻搜索算法的计算负担，而使用KD树来处理大数据集和局部敏感散列（LSH）来提供近似最近邻，即使在高维空间中也是可行的。

will take a deep dive into two critical components of the algorithms: the data representation and metric for measuring similarity between pairs of datapoints. You will examine the computational burden of the naive nearest neighbor search algorithm, and instead implement scalable alternatives using KD-trees for handling large datasets and locality sensitive hashing (LSH) for providing approximate nearest neighbors, even in high-dimensional spaces. 

<br /> <br />

* **Clustering with k-means聚类和K-means**

将实现的第一个聚类算法是k-means，它是最广泛使用的聚类算法。 要扩展k-means，将了解一般的MapReduce框架来并行和分发计算，然后k-means的迭代可以如何利用此框架。 k-means可以在适当调整时提供维基百科文章的可解释组

The first clustering algorithm you will implement is k-means, which is the most widely used clustering algorithm out there. To scale up k-means, you will learn about the general MapReduce framework for parallelizing and distributing computations, and then how the iterates of k-means can utilize this framework. You will show that k-means can provide an interpretable grouping of Wikipedia articles when appropriately tuned

 <br /> <br />

* **Mixture Models混合模型**

您将探索并实施一个广泛有用的算法，称为期望最大化（EM），用于推断这些软分配以及模型参数。
You will explore and implement a broadly useful algorithm called expectation maximization (EM) for inferring these soft assignments, as well as the model parameters.

 <br /> <br />
 

* **Mixed Membership Modeling & Latent Dirichlet Allocation 混合主题模型和LDA**

将解释LDA的输出，以及可以利用输出的各种方式，如一组学习的文档特征。 您通过LDA获得的用于文档分析的混合会员建模思想可以传递到许多其他有趣的模型和应用程序，例如人们拥有多个关联的社交网络模型

will interpret the output of LDA, and various ways the output can be utilized, like as a set of learned document features. The mixed membership modeling ideas you learn about through LDA for document analysis carry over to many other interesting models and applications, like social network models where people have multiple affiliations
 <br /> <br />

* **Hierarchical Clustering & Closing Remarks层次聚类和结束语**

我们提供一个称为层次聚类的替代聚类方法的快速浏览，您将在维基百科数据集上进行实验。 在进行这一探索之后，我们将讨论如何将分组类型的想法应用于其他领域，如分段时间序列。
We provide a quick tour into an alternative clustering approach called hierarchical clustering, which you will experiment with on the Wikipedia dataset. Following this exploration, we discuss how clustering-type ideas can be applied in other areas like segmenting time series. 
 <br /> <br />
 
* For more information：go https://www.coursera.org/learn/ml-foundations
 <br />

## Author
[MingJun Li](https://github.com/littlewizardLI)

## License
[MIT license](https://github.com/littlewizardLI/LICENSE)
